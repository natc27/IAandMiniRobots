{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc3ad461",
   "metadata": {},
   "source": [
    "# Capítulo 5. Redes neuronales.\n",
    "> Autor: Natalia Cely Callejas, Ronald Arturo Chavez.\\\n",
    "> Universidad Nacional de Colombia  \n",
    "> Julio 3, 2025\n",
    "\n",
    "## Introducción\n",
    "Las redes neuronales son sistemas bioinspirados en el funcionamiento del cerebro humano, compuesto por neuronas artificiales distribuidas en tres capas principales: *Input*, *Hidden* y *Output*. Estos sistemas se entrenan basados en diferentes variables cuya influencia en el resultado se determina con pesos y sesgos, esto modifica los resultados entregados en función de su validación con los valores correctos y por medio de refuerzos/penalización a través de una base de datos extensa y representativa. Generalmente, son utilizadas con fines de clasificación, predicción, reconocimiento de voz y procesamiento de lenguaje.\n",
    "\n",
    "## Ejemplo MEPX con Redes Neuronales\n",
    "aaaaa\n",
    "\n",
    "## Clasificación de prendas de vestir por redes neuronales\n",
    "Haciendo uso del data set Fashion del MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cb4eb26",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#----------\n",
    "# Cargar el dataset Fashion MNIST y dividirlo para su entrenamiento y validación\n",
    "#----------\n",
    "\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "#-------------\n",
    "# Nombres de las clases/labels 0-9 según repositorio\n",
    "#--------------\n",
    "\n",
    "nombres_clases = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "                  'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "#-----------\n",
    "# Normalizar los datos (0-1)\n",
    "#-----------\n",
    "\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "#-----------\n",
    "# Definir el modelo secuencial\n",
    "#-----------\n",
    "\n",
    "modelo = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),         # Capa de entrada\n",
    "    tf.keras.layers.Dense(128, activation='relu'),         # Capa oculta\n",
    "    tf.keras.layers.Dense(10, activation='softmax')        # Capa de salida (10 clases)\n",
    "])\n",
    "\n",
    "#-----------\n",
    "# Compilación del modelo\n",
    "#-----------\n",
    "\n",
    "modelo.compile(optimizer='adam',\n",
    "               loss='sparse_categorical_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "#-----------\n",
    "# Entrenar el modelo\n",
    "#-----------\n",
    "\n",
    "modelo.fit(x_train, y_train, epochs=10)\n",
    "\n",
    "#-----------\n",
    "# Evaluar en test\n",
    "#-----------\n",
    "\n",
    "test_loss, test_acc = modelo.evaluate(x_test, y_test)\n",
    "print(f\"\\nPrecisión en test: {test_acc:.2%}\")\n",
    "\n",
    "#----------\n",
    "# Predecir\n",
    "#----------\n",
    "\n",
    "predicciones = modelo.predict(x_test)\n",
    "\n",
    "#----------\n",
    "# Visualizar 5 predicciones\n",
    "#----------\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "for i in range(5):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_test[i], cmap=plt.cm.binary)\n",
    "    pred = np.argmax(predicciones[i])\n",
    "    plt.xlabel(f\"{nombres_clases[pred]}\\n(Verdad: {nombres_clases[y_test[i]]})\", color=\"green\" if pred == y_test[i] else \"red\")\n",
    "plt.suptitle(\"Ejemplos de predicción\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf93bbd",
   "metadata": {},
   "source": [
    "Data set Red neuronal Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92ac7427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USUARIO\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.8667 - loss: 0.5095\n",
      "\n",
      "Precisión del modelo en datos de prueba: 0.87\n",
      "\n",
      "Ejemplo de entrada escalado: [ 0.31099753 -0.59237301  0.53540856  0.00087755]\n",
      "\n",
      "Activaciones capa 1 (ReLU): [0.         0.6884743  0.50125635 0.         0.57482839 0.54074957\n",
      " 0.04678785 0.         0.39399499 0.35141836]\n",
      "\n",
      "Probabilidades (Softmax): [0.13056058 0.47770007 0.39173935]\n",
      "Clase predicha: 1\n",
      "Clase real: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(10, activation='relu', input_shape=(4,)),  # Capa oculta\n",
    "    Dense(3, activation='softmax')  # Capa de salida\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=50, verbose=0)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"\\nPrecisión del modelo en datos de prueba: {accuracy:.2f}\")\n",
    "\n",
    "weights_layer1, biases_layer1 = model.layers[0].get_weights()\n",
    "weights_layer2, biases_layer2 = model.layers[1].get_weights()\n",
    "\n",
    "# Usar un ejemplo con los pesos aprendidos\n",
    "x_input = X_test[0]\n",
    "print(\"\\nEjemplo de entrada escalado:\", x_input)\n",
    "\n",
    "z1 = np.dot(x_input, weights_layer1) + biases_layer1\n",
    "a1 = np.maximum(0, z1)  # ReLU\n",
    "print(\"\\nActivaciones capa 1 (ReLU):\", a1)\n",
    "\n",
    "z2 = np.dot(a1, weights_layer2) + biases_layer2\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "output_probs = softmax(z2)\n",
    "predicted_class = np.argmax(output_probs)\n",
    "\n",
    "print(\"\\nProbabilidades (Softmax):\", output_probs)\n",
    "print(\"Clase predicha:\", predicted_class)\n",
    "print(\"Clase real:\", y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dd3a8f",
   "metadata": {},
   "source": [
    "## Aporte de LLMs.\n",
    "\n",
    " En la red neuronal Iris recurrí al apoyo de una herramienta de lenguaje grande (LLM), ChatGPT, para resolver obstáculos técnicos específicos y agilizar el aprendizaje. También actuó como un asistente técnico complementario, facilitando el avance continuo del trabajo y promoviendo una comprensión más profunda del funcionamiento de las redes neuronales artificiales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228ebba8",
   "metadata": {},
   "source": [
    "## Conclusiones. \n",
    "El desarrollo de una red neuronal artificial para la clasificación del conjunto de datos Iris permitió comprender de manera integral tanto los fundamentos teóricos como la aplicación práctica del aprendizaje automático supervisado. A través del diseño del modelo, la selección de funciones de activación adecuadas, el entrenamiento con datos normalizados y la evaluación de su desempeño, fue posible evidenciar cómo una red neuronal transforma los datos de entrada en decisiones predictivas mediante el ajuste de pesos internos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
